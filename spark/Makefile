.PHONY: help up up-scaled down downall destroy logs status

# Default target - show help when just typing 'make'
default: help

# Show help information
help: ## Show this help message
	@echo "Spark Cluster Management"
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "  %-12s %s\n", $$1, $$2}'

# Start Spark cluster with 1 worker
up: ## Start Spark cluster with 1 worker
	@echo "ðŸš€ Starting Spark cluster..."
	docker compose up -d
	@echo "âœ… Spark cluster started!"
	@echo ""
	@echo "ðŸ“‹ Spark Information:"
	@if [ -f .env ]; then \
		MASTER_UI_PORT=$$(grep '^SPARK_MASTER_WEB_UI_PORT=' .env | cut -d'=' -f2); \
		WORKER_UI_PORT=$$(grep '^SPARK_WORKER_WEB_UI_PORT=' .env | cut -d'=' -f2); \
		echo "   Spark Master UI: http://localhost:$$MASTER_UI_PORT"; \
		echo "   Spark Worker UI: http://localhost:$$WORKER_UI_PORT"; \
	else \
		echo "   Spark Master UI: http://localhost:8080"; \
		echo "   Spark Worker UI: http://localhost:8081"; \
	fi
	@echo ""
	@echo "ðŸ’¡ Use 'make logs' to watch Spark logs"
	@echo "ðŸ’¡ Use 'make status' to check container status"

# Start Spark cluster with 3 workers
up-scaled: ## Start Spark cluster with 3 workers
	@echo "ðŸš€ Starting Spark cluster with 3 workers..."
	docker compose up -d --scale spark-worker=3
	@echo "âœ… Spark cluster with 3 workers started!"
	@echo ""
	@echo "ðŸ“‹ Spark Information:"
	@if [ -f .env ]; then \
		MASTER_UI_PORT=$$(grep '^SPARK_MASTER_WEB_UI_PORT=' .env | cut -d'=' -f2); \
		echo "   Spark Master UI: http://localhost:$$MASTER_UI_PORT"; \
	else \
		echo "   Spark Master UI: http://localhost:8080"; \
	fi
	@echo "   Worker UIs: http://localhost:8081, http://localhost:8082, http://localhost:8083"
	@echo ""
	@echo "ðŸ’¡ Use 'make logs' to watch Spark logs"
	@echo "ðŸ’¡ Use 'make status' to check container status"

# Stop Spark cluster
down: ## Stop Spark cluster
	@echo "ðŸ›‘ Stopping Spark cluster..."
	docker compose down
	@echo "âœ… Spark cluster stopped!"

# Stop and remove Spark cluster, networks, and volumes
downall: ## Stop and remove containers, networks, and volumes
	@echo "ðŸ§¹ Stopping and removing containers, networks, and volumes..."
	docker compose down --volumes --remove-orphans
	@echo "âœ… Complete cleanup finished!"

# Clean up all Docker artifacts generated by this project
destroy: ## Clean up all Docker artifacts generated by this project
	@echo "ðŸ§¹ Destroying all Docker artifacts for this project..."
	docker compose down --volumes --remove-orphans --rmi all
	@echo "âœ… Docker cleanup complete!"

# Watch logs from Spark cluster
logs: ## Watch logs from Spark cluster
	@echo "ðŸ“‹ Watching Spark logs (press Ctrl+C to exit)..."
	@echo ""
	docker compose logs -f

# Show status of Spark containers
status: ## Show status of Spark containers
	@echo "ðŸ“Š Spark Container Status:"
	@echo ""
	@docker compose ps
	@echo ""
	@echo "ðŸ“¦ Spark Volumes:"
	@docker volume ls | grep spark || echo "No Spark volumes found"

